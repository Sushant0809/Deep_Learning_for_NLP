{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671715ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 14:44:10.341114: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, Input, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, concatenate,Flatten\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a748d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('/Vol1/sushant/Script/Assignment 1/ClassificationDataset-train2.xlsx')\n",
    "val = pd.read_excel('/Vol1/sushant/Script/Assignment 1/ClassificationDataset-valid2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b9b32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "val.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d251aee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 10000\n",
    "max_len = 100\n",
    "embedding_dim = 200  # Correct the embedding dimension to match GloVe embeddings\n",
    "num_classes = len(np.unique(train['ClassLabel']))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2501bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train['ClassLabel'])\n",
    "\n",
    "train_labels_encoded = le.transform(train['ClassLabel'])\n",
    "val_labels_encoded = le.transform(val['ClassLabel'])\n",
    "train_labels_onehot = np.eye(num_classes)[train_labels_encoded]\n",
    "val_labels_onehot = np.eye(num_classes)[val_labels_encoded]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c16c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train['ReviewText'])\n",
    "train_sequences = tokenizer.texts_to_sequences(train['ReviewText'])\n",
    "val_sequences = tokenizer.texts_to_sequences(val['ReviewText'])\n",
    "train_data_pad = pad_sequences(train_sequences, maxlen=max_len)\n",
    "val_data_pad = pad_sequences(val_sequences, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875a5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "with open('/Vol1/sushant/Script/Assignment 1/glove.twitter.27B.200d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coef = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coef\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd76230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 100, 200)     2000000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 100, 256)     336896      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 100, 256)     0           ['bidirectional[0][0]',          \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 256)         394240      ['attention[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (None, 256)          0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5)            1285        ['attention_1[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,732,421\n",
      "Trainable params: 732,421\n",
      "Non-trainable params: 2,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(max_words, embedding_dim, input_length=max_len, weights=[embedding_matrix], trainable=False)\n",
    "input_layer = Input(shape=(max_len,))\n",
    "embedded_sequences = embedding_layer(input_layer)\n",
    "# Word-level Bi-LSTM\n",
    "word_lstm = Bidirectional(LSTM(128, return_sequences=True))(embedded_sequences)\n",
    "# Word-level attention\n",
    "word_attention = Attention()([word_lstm, word_lstm])\n",
    "# Sentence-level Bi-LSTM\n",
    "sentence_lstm = Bidirectional(LSTM(128, return_sequences=False))(word_attention)\n",
    "# Sentence-level attention\n",
    "sentence_attention = Attention()([sentence_lstm, sentence_lstm])\n",
    "# Document classifier\n",
    "output_layer = Dense(num_classes, activation='softmax')(sentence_attention)\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63bb39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5aa1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a50a429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 19:22:44.733785: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"111\" frequency: 2400 num_cores: 40 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 26214400 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.7566 - accuracy: 0.8016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 19:22:57.361689: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"111\" frequency: 2400 num_cores: 40 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 26214400 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 19s 314ms/step - loss: 0.7566 - accuracy: 0.8016 - val_loss: 0.7343 - val_accuracy: 0.8002\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 17s 392ms/step - loss: 0.7324 - accuracy: 0.8016 - val_loss: 0.7338 - val_accuracy: 0.8002\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 17s 393ms/step - loss: 0.7292 - accuracy: 0.8016 - val_loss: 0.7348 - val_accuracy: 0.8002\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 16s 366ms/step - loss: 0.7284 - accuracy: 0.8016 - val_loss: 0.7304 - val_accuracy: 0.8002\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 17s 380ms/step - loss: 0.7283 - accuracy: 0.8016 - val_loss: 0.7315 - val_accuracy: 0.8002\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 17s 380ms/step - loss: 0.7275 - accuracy: 0.8016 - val_loss: 0.7333 - val_accuracy: 0.8002\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 16s 374ms/step - loss: 0.7319 - accuracy: 0.8016 - val_loss: 0.7394 - val_accuracy: 0.8002\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 0.7266 - accuracy: 0.8016 - val_loss: 0.7315 - val_accuracy: 0.8002\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 17s 397ms/step - loss: 0.7276 - accuracy: 0.8016 - val_loss: 0.7262 - val_accuracy: 0.8002\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 16s 370ms/step - loss: 0.7092 - accuracy: 0.8016 - val_loss: 0.7113 - val_accuracy: 0.8002\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 17s 392ms/step - loss: 0.6977 - accuracy: 0.8016 - val_loss: 0.6882 - val_accuracy: 0.8002\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 17s 391ms/step - loss: 0.6889 - accuracy: 0.8016 - val_loss: 0.6848 - val_accuracy: 0.8002\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.6613 - accuracy: 0.8016 - val_loss: 0.6418 - val_accuracy: 0.8002\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 17s 388ms/step - loss: 0.6494 - accuracy: 0.8034 - val_loss: 0.6381 - val_accuracy: 0.8002\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 16s 372ms/step - loss: 0.6018 - accuracy: 0.8127 - val_loss: 0.5989 - val_accuracy: 0.8102\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 18s 400ms/step - loss: 0.5822 - accuracy: 0.8162 - val_loss: 0.5947 - val_accuracy: 0.8118\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 17s 393ms/step - loss: 0.5833 - accuracy: 0.8091 - val_loss: 0.6124 - val_accuracy: 0.8127\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 17s 391ms/step - loss: 0.5566 - accuracy: 0.8202 - val_loss: 0.5978 - val_accuracy: 0.8102\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 17s 387ms/step - loss: 0.5384 - accuracy: 0.8277 - val_loss: 0.5918 - val_accuracy: 0.8068\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 17s 393ms/step - loss: 0.5187 - accuracy: 0.8305 - val_loss: 0.5858 - val_accuracy: 0.8135\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 0.5194 - accuracy: 0.8330 - val_loss: 0.5946 - val_accuracy: 0.8160\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 17s 399ms/step - loss: 0.5060 - accuracy: 0.8334 - val_loss: 0.6076 - val_accuracy: 0.8135\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 18s 400ms/step - loss: 0.4874 - accuracy: 0.8373 - val_loss: 0.6142 - val_accuracy: 0.8143\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 17s 380ms/step - loss: 0.4711 - accuracy: 0.8377 - val_loss: 0.6292 - val_accuracy: 0.8077\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.4588 - accuracy: 0.8416 - val_loss: 0.6314 - val_accuracy: 0.8035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e204dd630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_pad, train_labels_onehot, epochs=50, batch_size=64,\n",
    "          validation_data=(val_data_pad, val_labels_onehot),\n",
    "           callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9cbf3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 19:29:49.703318: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"111\" frequency: 2400 num_cores: 40 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 26214400 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 5s 87ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8118234804329725"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions = model.predict(val_data_pad)\n",
    "val_predictions_classes = np.argmax(val_predictions, axis=1)\n",
    "f1_scores = f1_score(val_labels_encoded, val_predictions_classes, average='micro')\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f3ec185",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dataset_2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
