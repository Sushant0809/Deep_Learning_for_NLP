{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe854067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import spacy\n",
    "from torchtext.vocab import GloVe, FastText\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import math\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e005073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''\n",
    "        For Reproducibility: Sets the seed of the entire notebook.\n",
    "    '''\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # Sets a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff48b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = open(\"./Assignment2aDataset.txt\", \"r\").read()\n",
    "dataset_lines = dataset_file.splitlines()\n",
    "\n",
    "dataset = []\n",
    "for line in dataset_lines:\n",
    "    x, y = line.split(',')\n",
    "    x, y = x.lower().strip()[1:-1], y.lower().strip()[1:-1]\n",
    "    \n",
    "    if '/' in x:\n",
    "        x = x.split('/')\n",
    "    else:\n",
    "        x = x.split(' ')\n",
    "        \n",
    "    dataset.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8339130",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_preprocessed = []\n",
    "\n",
    "for x, y in dataset:\n",
    "\n",
    "    x_prepro = []\n",
    "    for word in x:\n",
    "        x_prepro.append(word)\n",
    "\n",
    "    labels = []\n",
    "    for label in y:\n",
    "        if label == '-':\n",
    "            labels.append(10)\n",
    "        else:\n",
    "            labels.append(int(label))\n",
    "    dataset_preprocessed.append((x_prepro, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd59ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 7, 1, 2, 10, 0, 1, 10, 2, 7]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13183acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "vocab_to_ids = {}\n",
    "ids = 1\n",
    "for x, y in dataset_preprocessed:\n",
    "    for i in x:\n",
    "        vocabulary.add(i)\n",
    "        if i not in vocab_to_ids:\n",
    "            vocab_to_ids[i] = ids\n",
    "            ids += 1\n",
    "vocab_to_ids['unk'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97e3df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_corpus = []\n",
    "for x, y in dataset_preprocessed:\n",
    "    x_ids = []\n",
    "    for i in x:\n",
    "        x_ids.append(vocab_to_ids[i])\n",
    "    dataset_corpus.append((x_ids, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74aa448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads GloVe and FastText\n",
    "global_vectors = GloVe(name='840B', dim=300)\n",
    "\n",
    "emb_dim = 300\n",
    "embeds = torch.zeros(len(vocab_to_ids) + 1, emb_dim)\n",
    "\n",
    "for token, idx in vocab_to_ids.items():\n",
    "    embeds[idx] = global_vectors[token] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad14545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7f299b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Valid split of 80-20\n",
    "def split_indices(n, val_pct):\n",
    "\n",
    "    # Determine size of Validation set\n",
    "    n_val = int(val_pct * n)\n",
    "\n",
    "    # Create random permutation of 0 to n-1\n",
    "    idxs = np.random.permutation(n)\n",
    "    return idxs[n_val:], idxs[:n_val]\n",
    "\n",
    "train_indices, val_indices = split_indices(len(dataset_corpus), 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "071ec051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# ----------- Batching the data -----------\n",
    "def collate_fn(instn):\n",
    "    sentence = [torch.Tensor(x[0]) for x in instn]\n",
    "    labels = torch.Tensor([x[1] for x in instn])\n",
    "\n",
    "    padded_sent = pad_sequence(sentence, batch_first=True, padding_value=0)\n",
    "\n",
    "    l = torch.cat((labels[:, 0], labels[:, 1],labels[:, 2],labels[:, 3],labels[:, 4],labels[:, 5],labels[:, 6],labels[:, 7],labels[:, 8],labels[:, 9]), dim = 0)\n",
    "\n",
    "    return (padded_sent.long(), l.long())\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_sampler   = SubsetRandomSampler(train_indices)\n",
    "train_loader    = DataLoader(dataset_corpus, batch_size, sampler=train_sampler, collate_fn=collate_fn)\n",
    "\n",
    "val_sampler     = SubsetRandomSampler(val_indices)\n",
    "val_loader      = DataLoader(dataset_corpus, batch_size, sampler=val_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a3221e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 3, 0, 10, 0, 5, 10, 0, 9]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_loader.dataset[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6185e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:1\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2dcb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransformerEncoder(nn.Module):\n",
    "#     def __init__(self, embeds, num_layers, num_heads, hidden_dim, dropout, max_seq_length):\n",
    "#         super(TransformerEncoder, self).__init__()\n",
    "#         self.embedding = nn.Embedding.from_pretrained(embeds, padding_idx=0, freeze=False)\n",
    "#         self.positional_embedding = nn.Embedding(max_seq_length, emb_dim)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#         self.transformer_layers = nn.ModuleList([\n",
    "#             nn.TransformerEncoderLayer(\n",
    "#                 d_model=emb_dim,\n",
    "#                 nhead=num_heads,\n",
    "#                 dim_feedforward=hidden_dim,\n",
    "#                 dropout=dropout\n",
    "#             ) for _ in range(num_layers)\n",
    "#         ])\n",
    "\n",
    "#         # Define the classifier to map the embedding dimension to the number of classes\n",
    "#         self.classifier = nn.Linear(emb_dim * 4, 10) \n",
    "\n",
    "#     def forward(self, src):\n",
    "#         # Error checking\n",
    "#         if src.shape[1] > max_seq_length:\n",
    "#             raise ValueError(f\"Input sequence length ({src.shape[1]}) exceeds max_seq_length ({max_seq_length}). Consider increasing max_seq_length.\")\n",
    "\n",
    "#         # Create a tensor of positional indices\n",
    "#         positions = torch.arange(0, src.shape[1], dtype=torch.long, device=src.device).unsqueeze(0).repeat(src.shape[0], 1)\n",
    "\n",
    "#         # Get word embeddings and positional embeddings\n",
    "#         word_embeddings = self.embedding(src)\n",
    "#         pos_embeddings = self.positional_embedding(positions)\n",
    "\n",
    "#         # Sum the embeddings and apply dropout\n",
    "#         x = word_embeddings + pos_embeddings\n",
    "#         x = self.dropout(x)\n",
    "\n",
    "#         # Pass through transformer layers\n",
    "#         for layer in self.transformer_layers:\n",
    "#             x = layer(x)\n",
    "    \n",
    "# #         print(x.shape)\n",
    "        \n",
    "#         x=x.view(x.size(0), -1)\n",
    "# #         print(x.shape)\n",
    "#         # Pass through the classifier\n",
    "#         x = self.classifier(x)\n",
    "# #         print(x.shape)\n",
    "    \n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "# # # Define the TransformerModel class with separate trg_max_seq_length and output_dim\n",
    "# # class TransformerModel(nn.Module):\n",
    "# #     def __init__(self, src_embeds, trg_embeds, num_layers, num_heads, hidden_dim, output_dim, dropout, src_max_seq_length, trg_max_seq_length):\n",
    "# #         super(TransformerModel, self).__init__()\n",
    "# #         self.encoder = TransformerEncoder(src_embeds, num_layers, num_heads, hidden_dim, dropout, src_max_seq_length)\n",
    "# #         self.decoder = TransformerDecoder(trg_embeds, num_layers, num_heads, hidden_dim, output_dim, dropout, trg_max_seq_length)\n",
    "\n",
    "# #     def forward(self, src, trg):\n",
    "# #         enc_output = self.encoder(src)\n",
    "# #         output = self.decoder(trg, enc_output)\n",
    "# #         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67e115a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        d_k = q.size(-1)\n",
    "        attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "        attn_logits = attn_logits / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            attn_logits = attn_logits.masked_fill(mask == 0, -1e9)\n",
    "        attn_weights = F.softmax(attn_logits, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        output = torch.matmul(attn_weights, v)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "        self.attn = ScaledDotProductAttention(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.size(0)\n",
    "        q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        output = self.attn(q, k, v, mask)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
    "        output = self.output_linear(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length=100):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = self.create_pos_embedding(d_model, max_seq_length)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_pos_embedding(d_model, max_seq_length):\n",
    "        pos_embedding = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pos_embedding[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_embedding[:, 1::2] = torch.cos(position * div_term)\n",
    "        pos_embedding = pos_embedding.unsqueeze(0)\n",
    "        return pos_embedding\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_embedding[:, :x.size(1)].to(x.device)\n",
    "    \n",
    "    \n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(num_heads, d_model)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, d_model)\n",
    "        )\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_output = self.attn(x, x, x, mask)\n",
    "        x = self.layer_norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.layer_norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "  \n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embeds, num_layers, num_heads, hidden_dim, dropout, max_seq_length):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeds, padding_idx=0, freeze=False)\n",
    "        self.pos_enc = PositionalEncoding(embeds.size(1), max_seq_length)\n",
    "        self.encoder_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlock(embeds.size(1), num_heads, hidden_dim, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.output_linear = nn.Linear(embeds.size(1), output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.pos_enc(x)\n",
    "        for encoder_block in self.encoder_blocks:\n",
    "            x = encoder_block(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.output_linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ccbd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(y_hat, yb):\n",
    "    num_batches = yb.shape[0] // 10  # Calculate the number of batches (assuming 10 samples per batch)\n",
    "    correct_batches = 0  # Initialize a counter for correctly predicted batches\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        batch_start_idx = batch_idx * 10\n",
    "        batch_end_idx = (batch_idx + 1) * 10\n",
    "\n",
    "        true_labels_batch = yb[batch_start_idx:batch_end_idx]  # Extract true labels for the current batch\n",
    "        predicted_labels_batch = y_hat[batch_start_idx:batch_end_idx]  # Extract predicted labels for the current batch\n",
    "\n",
    "        # Check if all predicted labels in the batch match the true labels\n",
    "        if (true_labels_batch == predicted_labels_batch).all():\n",
    "            correct_batches += 1  # Increment the counter if all predictions in the batch are correct\n",
    "\n",
    "    return correct_batches, num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceb613c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (embeddings): Embedding(699, 300, padding_idx=0)\n",
       "  (pos_enc): PositionalEncoding()\n",
       "  (encoder_blocks): ModuleList(\n",
       "    (0-5): 6 x TransformerEncoderBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (attn): ScaledDotProductAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=300, bias=True)\n",
       "      )\n",
       "      (layer_norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (output_linear): Linear(in_features=300, out_features=699, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the Transformer encoder-only model\n",
    "max_seq_length = 100  # Adjust as needed\n",
    "emb_dim = 300  # Embedding dimension, should match your pretrained embeddings\n",
    "num_layers = 6  # Number of transformer layers\n",
    "num_heads = 6  # Number of attention heads\n",
    "hidden_dim = 512  # Hidden dimension of the feedforward layers\n",
    "output_dim = len(vocab_to_ids) + 1  # Output dimension, including the \"unk\" token\n",
    "dropout = 0.2  # Dropout rate\n",
    "\n",
    "# Initialize the Transformer encoder-only model\n",
    "model = TransformerEncoder(embeds, num_layers, num_heads, hidden_dim, dropout, max_seq_length)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7aefc01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (64) to match target batch_size (640).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m model(xb) \n\u001b[0;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (64) to match target batch_size (640)."
     ]
    }
   ],
   "source": [
    "max_epoch = 20\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "min_val_loss = float('inf')\n",
    "prev_val_loss = float('inf')\n",
    "\n",
    "for ep in range(max_epoch):\n",
    "    # Training Loop\n",
    "    model.train()\n",
    "    train_labels = []\n",
    "    train_pred = []\n",
    "    correct_train, B_train = 0, 0\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for xb, yb in tqdm(train_loader):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        \n",
    "        y_hat = model(xb) \n",
    "        loss = loss_fn(y_hat, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += float(loss)\n",
    "\n",
    "        y_hat_labels = y_hat.argmax(dim=1)\n",
    "        correct_train += (y_hat_labels == yb.argmax(dim=1)).sum().item()\n",
    "        B_train += xb.size(0)\n",
    "        train_labels.extend(yb.argmax(dim=1).cpu().detach().numpy())\n",
    "        train_pred.extend(y_hat_labels.cpu().detach().numpy())\n",
    "\n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "    print(f\"Epoch: {ep + 1}, Training Loss: {epoch_loss / len(train_loader)}\")\n",
    "    print(f\"Train accuracy: {accuracy_score(train_labels, train_pred) * 100}\")\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_epoch_loss = 0\n",
    "    val_labels = []\n",
    "    val_pred = []\n",
    "    correct_val, B_val = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(val_loader):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            y_hat = model(xb) \n",
    "            loss = loss_fn(y_hat, yb)\n",
    "\n",
    "            val_epoch_loss += float(loss)\n",
    "\n",
    "            y_hat_labels = y_hat.argmax(dim=1)\n",
    "            correct_val += (y_hat_labels == yb.argmax(dim=1)).sum().item()\n",
    "            B_val += xb.size(0)\n",
    "            val_labels.extend(yb.argmax(dim=1).cpu().detach().numpy())\n",
    "            val_pred.extend(y_hat_labels.cpu().detach().numpy())\n",
    "\n",
    "    val_losses.append(val_epoch_loss / len(val_loader))\n",
    "    print(f\"Validation loss: {val_epoch_loss / len(val_loader)}\")\n",
    "    print(f\"Validation accuracy: {accuracy_score(val_labels, val_pred) * 100}\")\n",
    "\n",
    "    # Save the best model based on validation loss\n",
    "    if ep > 4 and val_epoch_loss < min_val_loss:\n",
    "        print(\"---- Saving Model ----\")\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        min_val_loss = val_epoch_loss\n",
    "\n",
    "    # Implement early stopping based on validation loss\n",
    "    if ep > 4 and prev_val_loss - val_epoch_loss > 0.05:\n",
    "        print(\"---- Early Stopping ----\")\n",
    "        break\n",
    "\n",
    "    prev_val_loss = val_epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8eb26c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 699])\n",
      "torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "print(y_hat.shape)\n",
    "print(yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e27bd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edaabfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  1,  1,  1,  1,  1,  2,  1,  2],\n",
       "        [ 1,  1,  1,  1,  1,  1,  2,  2,  1,  2],\n",
       "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 1,  2,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 1,  1,  2,  1,  1,  2,  1,  2,  1,  1],\n",
       "        [ 1,  1,  1,  2,  1,  1,  2,  1,  1,  1],\n",
       "        [ 2,  1,  1,  1,  6,  8,  5,  9,  5,  7],\n",
       "        [ 9,  0,  6,  0,  9,  9,  7,  7,  8,  7],\n",
       "        [ 0,  0,  5,  0,  6,  9,  7,  9,  8,  6],\n",
       "        [ 5,  5,  8,  7,  7,  0,  7,  7,  9,  7],\n",
       "        [ 9,  5,  5,  7,  7,  9,  0,  6,  9,  0],\n",
       "        [ 7,  0,  7,  7,  7,  6,  7,  0,  9,  9],\n",
       "        [ 0,  5,  7,  7,  0,  6,  9,  7,  6,  0],\n",
       "        [ 5,  1,  6,  4,  5,  1,  6,  3,  2,  4],\n",
       "        [ 8,  6,  4,  8,  0,  6,  9,  5,  0,  9],\n",
       "        [ 9,  8,  1,  8,  5,  9,  4,  7,  5,  6],\n",
       "        [ 2,  3,  4,  3,  0,  9,  4,  6,  0,  4],\n",
       "        [ 2,  8,  6,  2,  1,  5,  4,  9,  8,  3],\n",
       "        [ 6,  1,  0,  2,  6,  2,  5,  7,  1,  9],\n",
       "        [ 0,  5,  6,  5,  4,  3,  5,  4,  6,  1],\n",
       "        [ 5,  0,  0,  2,  1,  5,  7,  5,  1,  9],\n",
       "        [ 3,  8,  8,  7,  0,  4,  0,  5,  1,  9],\n",
       "        [ 5,  3,  3,  9,  6,  7,  4,  6,  1,  3],\n",
       "        [ 6,  4,  0,  9,  3,  2,  3,  5,  3,  7],\n",
       "        [ 3,  8,  6,  0,  2,  2,  7,  5,  9,  6],\n",
       "        [ 6,  2,  5,  5,  7,  3, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [ 0,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  1,  0,  0,  0,  0,  1,  1,  0],\n",
       "        [ 0,  1,  0,  1,  0,  0,  1,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "        [ 1,  0,  0,  1,  1,  0,  1,  0,  0,  0],\n",
       "        [ 0,  1,  0,  0,  1,  0,  0,  1,  0,  1],\n",
       "        [ 0,  0,  0,  0,  6,  9,  4,  1,  8,  6],\n",
       "        [ 7,  9,  8,  7,  3,  4,  0,  7,  4,  2],\n",
       "        [ 4,  1,  2,  1,  1,  2,  2,  0,  2,  6],\n",
       "        [ 1,  7,  2,  1,  2,  7,  7,  4,  9,  3],\n",
       "        [ 3,  3,  2,  4,  1,  3,  6,  2,  1,  8],\n",
       "        [ 0,  8,  8,  2,  2,  1,  7,  7,  0,  7],\n",
       "        [ 4,  0,  8,  2,  7,  5,  3,  1, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [10, 10,  1,  3,  1,  2,  2,  2,  1,  0],\n",
       "        [ 1,  2,  0,  1,  0,  1,  1,  2,  2,  0],\n",
       "        [ 2,  2,  1,  0,  2,  3,  2,  2,  2,  2],\n",
       "        [ 1,  1,  2,  0,  2,  0,  1,  0,  1,  1],\n",
       "        [ 1,  0,  1,  0,  2,  0,  0,  1,  1,  2],\n",
       "        [ 0,  0,  2,  0,  2,  2,  1,  1,  0,  0],\n",
       "        [ 2,  0,  0,  2,  2,  0,  2,  0,  2,  8],\n",
       "        [ 7,  5,  7,  5,  2,  4,  5,  9,  9,  1],\n",
       "        [ 9,  4,  2,  8,  7,  7,  9,  1,  1,  0],\n",
       "        [ 5,  1,  1,  4,  5,  4,  3,  1,  2,  7],\n",
       "        [ 8,  2,  5,  3,  0,  1,  8,  5,  9,  8],\n",
       "        [ 7,  2,  7,  1,  2,  1,  0,  4,  9,  1],\n",
       "        [ 8,  7,  4,  1,  5,  2,  1,  6,  4,  4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fca89544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 699\n",
      "Max value in xb: 688\n",
      "Min value in xb: 0\n",
      "torch.Size([699, 300])\n",
      "torch.Size([64, 10]) torch.float32\n",
      "torch.Size([64, 10]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "vocab_size = model.embedding.num_embeddings\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Max value in xb: {torch.max(xb)}\")\n",
    "print(f\"Min value in xb: {torch.min(xb)}\")\n",
    "print(model.embedding.weight.shape)\n",
    "print(y_hat.shape, y_hat.dtype)\n",
    "print(yb.shape, yb.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cfb403b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Loss vs. Epoch\n",
    "epochs = range(1, max_epoch + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "317035e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 125/125 [00:02<00:00, 51.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.01435844127414748\n",
      "Test accuracy:  99.56375\n",
      "Test EM:  96.35000000000001\n",
      "Test accuracy position-wise:  [99.3625, 96.775, 99.9375, 99.6625, 100.0, 100.0, 99.9625, 100.0, 99.9875, 99.95]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def exact_match(y_hat, yb):\n",
    "    B = yb.shape[0] // 10       # Batch size\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(B):\n",
    "        f = True\n",
    "        for j in range(10):\n",
    "            if yb[i+(j*B)] != y_hat[i+(j*B)]:\n",
    "                f = False\n",
    "                break \n",
    "        if f: correct += 1\n",
    "\n",
    "    output_correct = [0 for i in range(10)]\n",
    "    for i in range(B):\n",
    "        for j in range(10):\n",
    "            if yb[i+(j*B)] == y_hat[i+(j*B)]:\n",
    "                output_correct[j] += 1\n",
    "    return correct, B, output_correct\n",
    "\n",
    "val_labels = []\n",
    "val_pred = []\n",
    "\n",
    "val_epoch_loss = 0\n",
    "correct_val, B_val = 0, 0\n",
    "out_correct = [0 for i in range(10)]\n",
    "with torch.no_grad():\n",
    "    for xb, yb in tqdm(val_loader):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        y_hat = model(xb)\n",
    "        loss = loss_fn(y_hat, yb)\n",
    "\n",
    "        val_epoch_loss += float(loss)\n",
    "\n",
    "        y_hat = torch.softmax(y_hat, dim = 1).argmax(dim=1)\n",
    "\n",
    "        correct, B, output_correct = exact_match(y_hat, yb)\n",
    "        correct_val += correct\n",
    "        B_val += B\n",
    "        for i in range(10):\n",
    "            out_correct[i] += output_correct[i]\n",
    "\n",
    "        val_labels.extend(yb.cpu().detach().numpy())\n",
    "        val_pred.extend(y_hat.cpu().detach().numpy())\n",
    "\n",
    "val_epoch_loss = val_epoch_loss / len(val_loader)\n",
    "print(\"Test loss: \", val_epoch_loss)\n",
    "print(\"Test accuracy: \", accuracy_score(val_labels, val_pred)*100)\n",
    "print(\"Test EM: \", (correct_val/ B_val)*100)\n",
    "for i in range(10):\n",
    "    out_correct[i] = (out_correct[i] / B_val) * 100\n",
    "print(\"Test accuracy position-wise: \", out_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "857778e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Set Error (Exact Match) in %: 3.6499999999999977\n",
      "Average Validation Set Error (Mismatch) in %: 1.244546875\n",
      "Output with Highest Error: 5\n",
      "Output with Lowest Error: 2\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average Exact Match Error\n",
    "average_exact_match_error = (1 - (correct_val / B_val)) * 100\n",
    "\n",
    "# Calculate the average Mismatch Error\n",
    "average_mismatch_error = ((sum(out_correct) / 10) / B_val) * 100\n",
    "\n",
    "# Find the output with the highest error\n",
    "highest_error_output = out_correct.index(max(out_correct)) + 1\n",
    "\n",
    "# Find the output with the lowest error\n",
    "lowest_error_output = out_correct.index(min(out_correct)) + 1\n",
    "\n",
    "# Print the results\n",
    "print(\"Average Validation Set Error (Exact Match) in %:\", average_exact_match_error)\n",
    "print(\"Average Validation Set Error (Mismatch) in %:\", average_mismatch_error)\n",
    "print(\"Output with Highest Error:\", highest_error_output)\n",
    "print(\"Output with Lowest Error:\", lowest_error_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03693395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
